{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d4dc07",
   "metadata": {},
   "source": [
    "# Cognitive Workspace Monorepo Structure Verification\n",
    "\n",
    "This notebook contains tests to verify the correct setup of the monorepo structure for the Cognitive Workspace application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2762b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install termcolor\n",
    "\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import unittest\n",
    "# from termcolor import colored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d36f41",
   "metadata": {},
   "source": [
    "## Directory Structure Tests\n",
    "\n",
    "These tests verify the existence of core directories in the monorepo structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectoryStructureTests(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Navigate to project root (assuming this notebook is in the project root)\n",
    "        self.project_root = Path(os.getcwd())\n",
    "\n",
    "    def test_core_directories_exist(self):\n",
    "        \"\"\"Test that all core directories exist\"\"\"\n",
    "        required_dirs = ['backend', 'frontend', 'shared', 'infrastructure']\n",
    "\n",
    "        for dir_name in required_dirs:\n",
    "            dir_path = self.project_root / dir_name\n",
    "            self.assertTrue(dir_path.exists(), f\"Directory '{dir_name}' does not exist\")\n",
    "            self.assertTrue(dir_path.is_dir(), f\"'{dir_name}' is not a directory\")\n",
    "\n",
    "    def test_backend_subdirectories(self):\n",
    "        \"\"\"Test that backend has appropriate subdirectories\"\"\"\n",
    "        backend_dir = self.project_root / 'backend'\n",
    "        # Assuming backend follows a modular structure\n",
    "        expected_subdirs = ['api', 'core', 'infrastructure', 'scripts', 'tests']\n",
    "\n",
    "        for subdir in expected_subdirs:\n",
    "            subdir_path = backend_dir / subdir\n",
    "            self.assertTrue(subdir_path.exists(), f\"Backend subdirectory '{subdir}' does not exist\")\n",
    "            self.assertTrue(subdir_path.is_dir(), f\"Backend '{subdir}' is not a directory\")\n",
    "\n",
    "    def test_frontend_subdirectories(self):\n",
    "        \"\"\"Test that frontend has appropriate subdirectories\"\"\"\n",
    "        frontend_dir = self.project_root / 'frontend'\n",
    "        expected_subdirs = ['src', 'public', 'tests']\n",
    "\n",
    "        for subdir in expected_subdirs:\n",
    "            subdir_path = frontend_dir / subdir\n",
    "            self.assertTrue(subdir_path.exists(), f\"Frontend subdirectory '{subdir}' does not exist\")\n",
    "            self.assertTrue(subdir_path.is_dir(), f\"Frontend '{subdir}' is not a directory\")\n",
    "\n",
    "    def test_shared_directory_structure(self):\n",
    "        \"\"\"Test that shared directory has appropriate structure\"\"\"\n",
    "        shared_dir = self.project_root / 'shared'\n",
    "        expected_subdirs = ['types', 'utils', 'constants']\n",
    "\n",
    "        for subdir in expected_subdirs:\n",
    "            subdir_path = shared_dir / subdir\n",
    "            self.assertTrue(subdir_path.exists(), f\"Shared subdirectory '{subdir}' does not exist\")\n",
    "            self.assertTrue(subdir_path.is_dir(), f\"Shared '{subdir}' is not a directory\")\n",
    "\n",
    "    def test_infrastructure_directory_structure(self):\n",
    "        \"\"\"Test that infrastructure directory has appropriate structure\"\"\"\n",
    "        infra_dir = self.project_root / 'infrastructure'\n",
    "        expected_subdirs = ['terraform', 'docker', 'scripts']\n",
    "\n",
    "        for subdir in expected_subdirs:\n",
    "            subdir_path = infra_dir / subdir\n",
    "            self.assertTrue(subdir_path.exists(), f\"Infrastructure subdirectory '{subdir}' does not exist\")\n",
    "            self.assertTrue(subdir_path.is_dir(), f\"Infrastructure '{subdir}' is not a directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20613415",
   "metadata": {},
   "source": [
    "## Configuration Files Tests\n",
    "\n",
    "These tests verify the existence and correctness of essential configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationFilesTests(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.project_root = Path(os.getcwd())\n",
    "\n",
    "    def test_root_configuration_files_exist(self):\n",
    "        \"\"\"Test that essential root configuration files exist\"\"\"\n",
    "        required_files = [\n",
    "            'package.json',\n",
    "            'tsconfig.json',\n",
    "            '.gitignore',\n",
    "            'README.md',\n",
    "            '.prettierrc',\n",
    "            '.eslintrc.js',\n",
    "            '.husky/pre-commit'\n",
    "        ]\n",
    "\n",
    "        for file_name in required_files:\n",
    "            file_path = self.project_root / file_name\n",
    "            self.assertTrue(file_path.exists(), f\"Configuration file '{file_name}' does not exist\")\n",
    "\n",
    "    def test_package_json_workspaces(self):\n",
    "        \"\"\"Test that package.json has workspaces configuration\"\"\"\n",
    "        with open(self.project_root / 'package.json', 'r') as f:\n",
    "            package_json = json.load(f)\n",
    "\n",
    "        self.assertIn('workspaces', package_json, \"package.json does not have workspaces configuration\")\n",
    "        workspaces = package_json['workspaces']\n",
    "        expected_workspaces = ['frontend', 'shared', 'infrastructure']\n",
    "\n",
    "        for workspace in expected_workspaces:\n",
    "            self.assertTrue(any(ws.startswith(workspace) for ws in workspaces),\n",
    "                           f\"Workspace '{workspace}' not configured in package.json\")\n",
    "\n",
    "    def test_typescript_configuration(self):\n",
    "        \"\"\"Test that TypeScript configuration is properly set up\"\"\"\n",
    "        with open(self.project_root / 'tsconfig.json', 'r') as f:\n",
    "            tsconfig = json.load(f)\n",
    "\n",
    "        self.assertIn('compilerOptions', tsconfig, \"tsconfig.json does not have compilerOptions\")\n",
    "        self.assertIn('references', tsconfig, \"tsconfig.json does not have project references\")\n",
    "\n",
    "        # Check for strict mode\n",
    "        compiler_options = tsconfig['compilerOptions']\n",
    "        self.assertTrue(compiler_options.get('strict', False), \"TypeScript strict mode is not enabled\")\n",
    "\n",
    "    def test_gitignore_configuration(self):\n",
    "        \"\"\"Test that .gitignore has essential entries\"\"\"\n",
    "        with open(self.project_root / '.gitignore', 'r') as f:\n",
    "            gitignore_content = f.read()\n",
    "\n",
    "        essential_ignores = ['node_modules', 'dist', 'build', '.env', 'coverage', '.DS_Store']\n",
    "        for entry in essential_ignores:\n",
    "            self.assertIn(entry, gitignore_content, f\"'{entry}' not found in .gitignore\")\n",
    "\n",
    "    def test_readme_content(self):\n",
    "        \"\"\"Test that README.md has essential sections\"\"\"\n",
    "        with open(self.project_root / 'README.md', 'r') as f:\n",
    "            readme_content = f.read()\n",
    "\n",
    "        essential_sections = ['# Cognitive Workspace', 'Installation', 'Usage', 'Development', 'Structure']\n",
    "        for section in essential_sections:\n",
    "            self.assertIn(section, readme_content, f\"'{section}' section not found in README.md\")\n",
    "\n",
    "    def test_eslint_configuration(self):\n",
    "        \"\"\"Test that ESLint is properly configured\"\"\"\n",
    "        eslint_path = self.project_root / '.eslintrc.js'\n",
    "        self.assertTrue(eslint_path.exists(), \"ESLint configuration file does not exist\")\n",
    "\n",
    "        # Read as text since it's a JS file, not JSON\n",
    "        with open(eslint_path, 'r') as f:\n",
    "            eslint_content = f.read()\n",
    "\n",
    "        essential_configs = ['typescript', 'prettier', 'react']\n",
    "        for config in essential_configs:\n",
    "            self.assertIn(config, eslint_content.lower(), f\"ESLint configuration for '{config}' not found\")\n",
    "\n",
    "    def test_prettier_configuration(self):\n",
    "        \"\"\"Test that Prettier is properly configured\"\"\"\n",
    "        prettier_path = self.project_root / '.prettierrc'\n",
    "        self.assertTrue(prettier_path.exists(), \"Prettier configuration file does not exist\")\n",
    "\n",
    "        with open(prettier_path, 'r') as f:\n",
    "            prettier_config = json.load(f)\n",
    "\n",
    "        essential_keys = ['tabWidth', 'semi', 'singleQuote', 'printWidth']\n",
    "        for key in essential_keys:\n",
    "            self.assertIn(key, prettier_config, f\"Prettier configuration key '{key}' not found\")\n",
    "\n",
    "    def test_husky_configuration(self):\n",
    "        \"\"\"Test that Husky pre-commit hook is configured\"\"\"\n",
    "        husky_path = self.project_root / '.husky' / 'pre-commit'\n",
    "        self.assertTrue(husky_path.exists(), \"Husky pre-commit hook does not exist\")\n",
    "\n",
    "        with open(husky_path, 'r') as f:\n",
    "            hook_content = f.read()\n",
    "\n",
    "        # Check for common pre-commit tasks\n",
    "        common_tasks = ['lint-staged', 'prettier', 'eslint', 'test']\n",
    "        found_tasks = 0\n",
    "        for task in common_tasks:\n",
    "            if task in hook_content.lower():\n",
    "                found_tasks += 1\n",
    "\n",
    "        self.assertGreater(found_tasks, 0, \"No common pre-commit tasks found in Husky configuration\")\n",
    "\n",
    "    def test_backend_python_configuration(self):\n",
    "        \"\"\"Test that Python backend has proper configuration\"\"\"\n",
    "        backend_configs = [\n",
    "            'backend/pyproject.toml',\n",
    "            'backend/.flake8',\n",
    "            'backend/setup.py'\n",
    "        ]\n",
    "\n",
    "        for config in backend_configs:\n",
    "            config_path = self.project_root / config\n",
    "            self.assertTrue(config_path.exists(), f\"Backend configuration '{config}' does not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd855a",
   "metadata": {},
   "source": [
    "## Build Process Tests\n",
    "\n",
    "These tests verify that the monorepo can be built without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8cd757",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildProcessTests(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.project_root = Path(os.getcwd())\n",
    "\n",
    "    def test_npm_install(self):\n",
    "        \"\"\"Test that npm install runs without errors\"\"\"\n",
    "        try:\n",
    "            # Run npm install with --dry-run to check for errors without actually installing\n",
    "            result = subprocess.run(['npm', 'install', '--dry-run'],\n",
    "                                   cwd=self.project_root,\n",
    "                                   check=True,\n",
    "                                   capture_output=True,\n",
    "                                   text=True)\n",
    "            self.assertEqual(result.returncode, 0, \"npm install --dry-run failed\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            self.fail(f\"npm install --dry-run failed with error: {e.stderr}\")\n",
    "\n",
    "    def test_typescript_compilation(self):\n",
    "        \"\"\"Test that TypeScript code compiles without errors\"\"\"\n",
    "        try:\n",
    "            # Run TypeScript compilation check without emitting files\n",
    "            result = subprocess.run(['npx', 'tsc', '--noEmit'],\n",
    "                                   cwd=self.project_root,\n",
    "                                   check=True,\n",
    "                                   capture_output=True,\n",
    "                                   text=True)\n",
    "            self.assertEqual(result.returncode, 0, \"TypeScript compilation failed\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            self.fail(f\"TypeScript compilation failed with error: {e.stderr}\")\n",
    "\n",
    "    def test_build_script(self):\n",
    "        \"\"\"Test that build script exists and runs\"\"\"\n",
    "        with open(self.project_root / 'package.json', 'r') as f:\n",
    "            package_json = json.load(f)\n",
    "\n",
    "        self.assertIn('scripts', package_json, \"package.json does not have scripts section\")\n",
    "        self.assertIn('build', package_json['scripts'], \"package.json does not have build script\")\n",
    "\n",
    "        # Don't actually run the build as it might be time-consuming\n",
    "        # Just check that the script is defined\n",
    "        build_script = package_json['scripts']['build']\n",
    "        self.assertTrue(build_script, \"Build script is empty\")\n",
    "\n",
    "    def test_backend_build(self):\n",
    "        \"\"\"Test that Python backend can be built/installed\"\"\"\n",
    "        backend_dir = self.project_root / 'backend'\n",
    "        if not (backend_dir / 'pyproject.toml').exists():\n",
    "            self.skipTest(\"Backend pyproject.toml not found, skipping backend build test\")\n",
    "\n",
    "        try:\n",
    "            # Check that pip install would work, without actually installing\n",
    "            result = subprocess.run(['pip', 'install', '-e', '.', '--dry-run'],\n",
    "                                   cwd=backend_dir,\n",
    "                                   check=True,\n",
    "                                   capture_output=True,\n",
    "                                   text=True)\n",
    "            self.assertEqual(result.returncode, 0, \"Backend pip install failed\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            self.fail(f\"Backend pip install failed with error: {e.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324d2afd",
   "metadata": {},
   "source": [
    "## Linting and Type Checking Tests\n",
    "\n",
    "These tests verify that linting and type checking are properly configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LintingAndTypeCheckingTests(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.project_root = Path(os.getcwd())\n",
    "\n",
    "    def test_eslint_runs(self):\n",
    "        \"\"\"Test that ESLint runs without fatal errors\"\"\"\n",
    "        try:\n",
    "            # Check if ESLint is configured properly by running it in dry mode\n",
    "            result = subprocess.run(['npx', 'eslint', '--no-eslintrc', '--print-config', '.'],\n",
    "                                   cwd=self.project_root,\n",
    "                                   check=True,\n",
    "                                   capture_output=True,\n",
    "                                   text=True)\n",
    "            self.assertEqual(result.returncode, 0, \"ESLint configuration check failed\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            self.fail(f\"ESLint configuration is invalid: {e.stderr}\")\n",
    "\n",
    "    def test_prettier_runs(self):\n",
    "        \"\"\"Test that Prettier runs without fatal errors\"\"\"\n",
    "        try:\n",
    "            # Check if Prettier is configured properly by running it in check mode\n",
    "            result = subprocess.run(['npx', 'prettier', '--check', '--loglevel', 'error', '.prettierrc'],\n",
    "                                   cwd=self.project_root,\n",
    "                                   check=False,  # Don't fail if files aren't formatted\n",
    "                                   capture_output=True,\n",
    "                                   text=True)\n",
    "            self.assertEqual(result.returncode, 0, \"Prettier configuration check failed\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            self.fail(f\"Prettier configuration is invalid: {e.stderr}\")\n",
    "\n",
    "    def test_typescript_project_references(self):\n",
    "        \"\"\"Test that TypeScript project references are properly configured\"\"\"\n",
    "        with open(self.project_root / 'tsconfig.json', 'r') as f:\n",
    "            tsconfig = json.load(f)\n",
    "\n",
    "        self.assertIn('references', tsconfig, \"tsconfig.json does not have project references\")\n",
    "        references = tsconfig['references']\n",
    "        self.assertTrue(isinstance(references, list), \"references in tsconfig.json is not an array\")\n",
    "        self.assertTrue(len(references) > 0, \"No project references found in tsconfig.json\")\n",
    "\n",
    "        # Check that the referenced projects exist\n",
    "        for ref in references:\n",
    "            if 'path' in ref:\n",
    "                ref_path = self.project_root / ref['path'] / 'tsconfig.json'\n",
    "                self.assertTrue(ref_path.exists(), f\"Referenced project at '{ref['path']}' does not exist\")\n",
    "\n",
    "    def test_flake8_configuration(self):\n",
    "        \"\"\"Test that Flake8 is properly configured for Python code\"\"\"\n",
    "        flake8_path = self.project_root / 'backend' / '.flake8'\n",
    "        if not flake8_path.exists():\n",
    "            self.skipTest(\"Flake8 configuration file not found, skipping test\")\n",
    "\n",
    "        with open(flake8_path, 'r') as f:\n",
    "            flake8_content = f.read()\n",
    "\n",
    "        # Check for basic flake8 configuration sections\n",
    "        self.assertIn('[flake8]', flake8_content, \"Flake8 configuration is missing [flake8] section\")\n",
    "\n",
    "    def test_python_typing(self):\n",
    "        \"\"\"Test that Python code has type hints configuration\"\"\"\n",
    "        pyproject_path = self.project_root / 'backend' / 'pyproject.toml'\n",
    "        if not pyproject_path.exists():\n",
    "            self.skipTest(\"pyproject.toml not found, skipping Python typing test\")\n",
    "\n",
    "        with open(pyproject_path, 'r') as f:\n",
    "            pyproject_content = f.read()\n",
    "\n",
    "        # Check for mypy or some kind of typing tool configuration\n",
    "        typing_tools = ['mypy', 'typing', 'pyre', 'pyright']\n",
    "        typing_configured = any(tool in pyproject_content.lower() for tool in typing_tools)\n",
    "        self.assertTrue(typing_configured, \"No Python typing tool configuration found in pyproject.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8279a375",
   "metadata": {},
   "source": [
    "## Run All Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e148c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests():\n",
    "    \"\"\"Run all test classes and report results\"\"\"\n",
    "    print(colored(\"\\n=== Cognitive Workspace Monorepo Structure Verification ===\\n\", \"cyan\"))\n",
    "\n",
    "    test_classes = [\n",
    "        DirectoryStructureTests,\n",
    "        ConfigurationFilesTests,\n",
    "        BuildProcessTests,\n",
    "        LintingAndTypeCheckingTests\n",
    "    ]\n",
    "\n",
    "    overall_success = True\n",
    "\n",
    "    for test_class in test_classes:\n",
    "        suite = unittest.TestLoader().loadTestsFromTestCase(test_class)\n",
    "        result = unittest.TextTestRunner(verbosity=2).run(suite)\n",
    "\n",
    "        if not result.wasSuccessful():\n",
    "            overall_success = False\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "    if overall_success:\n",
    "        print(colored(\"✅ All monorepo structure tests passed! The monorepo is correctly set up.\", \"green\"))\n",
    "    else:\n",
    "        print(colored(\"❌ Some monorepo structure tests failed. Please fix the issues before proceeding.\", \"red\"))\n",
    "\n",
    "    return overall_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ad612",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    success = run_tests()\n",
    "    if not success:\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ac74f",
   "metadata": {},
   "source": [
    "## Recommendations and Next Steps\n",
    "\n",
    "Based on the test results, here are recommended actions to ensure your monorepo is fully set up:\n",
    "\n",
    "1. For any failing directory structure tests:\n",
    "   - Create the missing core directories\n",
    "   - Ensure the basic structure within each directory is correct\n",
    "\n",
    "2. For any failing configuration file tests:\n",
    "   - Add missing configuration files\n",
    "   - Correct any malformed JSON in existing files\n",
    "   - Ensure all required fields are present in package.json files\n",
    "\n",
    "3. For build process failures:\n",
    "   - Check package.json scripts for correct build commands\n",
    "   - Resolve any dependency issues\n",
    "   - Fix build errors in the codebase\n",
    "\n",
    "4. For linting issues:\n",
    "   - Add missing ESLint or Prettier configurations\n",
    "   - Resolve any lint errors in the codebase\n",
    "\n",
    "5. For type checking issues:\n",
    "   - Add missing TypeScript configurations\n",
    "   - Fix any type errors in the codebase\n",
    "\n",
    "Run this notebook again after making changes to verify that all issues have been resolved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
